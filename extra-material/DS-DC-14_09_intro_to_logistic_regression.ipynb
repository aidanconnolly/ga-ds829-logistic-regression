{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INTRODUCTION TO LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DO WORK\n",
    "\n",
    "Open up the lesson 9 notebook and make a copy with your name as usual\n",
    "\n",
    "Read through the following questions and brainstorm answers for each:\n",
    "- **Write down the differences between L1 and L2 regularization**\n",
    "  - What do they do?\n",
    "  - When should I use each?\n",
    "\n",
    "- **What are the main differences between linear and KNN models?**\n",
    "  - What is different about how they approach solving the problem? \n",
    "  - For example, what is interpretable about OLS compared to what's interpretable in KNN?\n",
    "\n",
    "- **What would be the advantage of using a linear model like OLS to solve a classification problem, compared to KNN?**\n",
    "\n",
    "- **What are some challenges for using OLS to solve a classification problem (say, if the values were either 1 or 0)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LEARNING OBJECTIVES\n",
    "\n",
    "\n",
    "Build a Logistic regression classification model using the scikit learn library\n",
    "Describe a sigmoid function, odds, and the odds ratio as well as how they relate to logistic regression\n",
    "Evaluate a model using metrics such as classification accuracy/error, confusion matrix, ROC/AUC curves, and loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PRE-WORK REVIEW\n",
    "\n",
    "Implement a linear model (LinearRegression) with sklearn\n",
    "\n",
    "Understand what a coefficient is\n",
    "\n",
    "Recall metrics such as accuracy and misclassification\n",
    "\n",
    "Recall the differences between L1 and L2 regularization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOGISTIC REGRESSION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Logistic regression is a linear approach to solving a classification problem.\n",
    "\n",
    "That is, we can use a linear model, similar to Linear regression, in order to solve if an item belongs or does not belong to a class label."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why might we use logistic regression over KNN for classification?**\n",
    "- Logistic regression can handle dimensionality better than KNN \n",
    "- We can influence dimensionality using L1 and L2 regularization\n",
    "- Most relationships can be summarized well using a line so this is a good first step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNOWLEDGE CHECK\n",
    "\n",
    "1. What is classification?\n",
    "2. Why is it difficult to use linear regression for classification?\n",
    "3. Is there anything about the X matrix that prevents us using linear regression for a classification problem?\n",
    "\n",
    "<!--\n",
    "ANSWER:\n",
    "1. A machine learning problem where we predict a class or discrete value\n",
    "2.\n",
    "- Regression results can have a value range from -∞ to ∞. Which neither corresponds to classes or probabilities. Regression does not know how to select a class and only works with continuous values.\n",
    "3. Not really, we didn't have to change much about X to use KNN after all.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import cross_validation\n",
    "from sklearn import grid_search\n",
    "from sklearn import metrics\n",
    "from sklearn import linear_model\n",
    "from sklearn import dummy\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\", font_scale=1)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load data\n",
    "df = pd.read_csv('assets/dataset/admissions.csv')\n",
    "\n",
    "# check first few rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for missing values in each column before dropping\n",
    "print \"Missing values:\"\n",
    "print df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# drop missing values if there are any\n",
    "if df.isnull().sum().sum():\n",
    "    print \"There are missing values\"\n",
    "    df = df.dropna()\n",
    "    print \"Missing values dropped\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for missing values in each column after dropping\n",
    "print \"Missing values:\"\n",
    "print df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get dummy variables for prestige\n",
    "df = df.join(pd.get_dummies(df['prestige'], prefix='prestige'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check for newly added columns\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# for now let's only look at the lowest prestige schools since they're acceptance rates are a bit higher\n",
    "df1 = df[df['prestige_1.0'] == 1].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let’s look at some approaches to make classification with regression feasible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIX 1:  PROBABILITY\n",
    "\n",
    "One approach is to predict the probability that an observation belongs to a certain class rather than predicting the class.\n",
    "\n",
    "That is, we can predict that a student has a 54% chance of being admitted.\n",
    "\n",
    "**Is there any kind of base rate?**\n",
    "\n",
    "When working with regression the simplest meaningful prediction was the mean. Our models our only useful if they do better than the mean.\n",
    "\n",
    "For classification we can look at the **prior probability** of a class.\n",
    "\n",
    "For example, roughly 700 of 2200 people from the Titanic survived.  Without knowing anything about the passengers or crew, the probability of survival would be ~0.32 (32%).\n",
    "\n",
    "We can then use a linear function to either increase or decrease the probability of an observation given the data about it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNOWLEDGE CHECK\n",
    "\n",
    "Recall the linear regression formula.\n",
    "\n",
    "$$y = \\alpha + \\beta X + \\epsilon$$\n",
    "\n",
    "1. The prior probability is most similar to which value in the ordinary least squares formula? (It's inuitively close, but mathematically not the same unless your data is normalized.)\n",
    "\n",
    "2. What if 97% of our data is one class. What is the accuracy if we just predict the most common class?\n",
    "\n",
    "<!--\n",
    "1. We are looking for the value that represents the average survival probability when excluding all other factors. That would be, alpha, the intercept.(You can think of a model that does not account for any other factors as one whose all Beta coefficients are zero)\n",
    "\n",
    "2. The accuracy would be 97%. That looks good on paper, but it's not very useful since we aren't getting insight. This is the well known problem of class imbalance. There are some solutions that involve using the appropriate evaluation metric, the appropriate algorithm, the appropriate experimental design, or the appropriate evaluation procedure. We can spend several classes talking about this, so we'll only go into one solution.\n",
    "-->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot a linear regression of admit on gre\n",
    "sns.lmplot('gre', 'admit', df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remember that linear regression with an intercept will ALWAYS go through the mean of Y and X\n",
    "# Plot a linear regression of admit on gre and label the average point\n",
    "print 'Admit rate: ', df1.admit.mean()\n",
    "print 'Average GRE: ', df1.gre.mean()\n",
    "sns.lmplot('gre', 'admit', df1)\n",
    "plt.plot(df1.gre.mean(), df1.admit.mean(), 'ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit the linear model shown above\n",
    "X = df1[['gre']]\n",
    "y = df1['admit']\n",
    "lm = linear_model.LinearRegression().fit(X, y)\n",
    "lm_pred = lm.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remember, we read this as a unit increase in GRE score leads to a unit increase in the probability of getting admitted\n",
    "lm.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot the model predictions\n",
    "plt.figure()\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, lm_pred, c='red')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNOWLEDGE CHECK\n",
    "\n",
    "What would be the problem with our predictions if the line of best fit had a very steep slope?\n",
    "<!--\n",
    "ANSWER:\n",
    "Our predictions might be greater than 1 or less than 0. In other words, they could fall outside the acceptable range for probabilities.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIX 2: SIGMOID FUNCTIONS AND LINK FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### SIGMOID FUNCTIONS\n",
    "\n",
    "A sigmoid function is a mathematical function that visually looks like an s.\n",
    "\n",
    "This allows us to take a infinite set of possible values and squeeze them into a range between 0 and 1.\n",
    "\n",
    "For classification, we need a distribution associated with categories:  given all events, what is the probability of a given event?\n",
    "\n",
    "Probabilities range from 0 to 1\n",
    "\n",
    "The sigmoid function that best allows for this is the logit function since its output ranges from 0 to 1; Others that are commonly used in machine learning are the cumulative normal distribution, the arc tangent, and hyperbolic tangent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LINK FUNCTIONS\n",
    "\n",
    "Linear models can be extended to generalized linear models using a link function.\n",
    "\n",
    "**What is a link function? (Sometimes refered to as a kernel)**\n",
    "\n",
    "Link functions allows us to build a relationship between a linear function and the mean of a distribution.\n",
    "\n",
    "This lets us create non-linear relationships\n",
    "\n",
    "For count data $(0, \\infty)$ we might use the exponential function\n",
    "$$y = e^{\\alpha + \\beta X}$$\n",
    "\n",
    "This takes values from ($-\\infty$, $\\infty$) and outputs values from $(0, \\infty)$\n",
    "\n",
    "\n",
    "\n",
    "For binary data we will use the logistic function\n",
    "\n",
    "$$y = \\frac{1}{1 + e^{-(\\alpha + \\beta X)}}$$\n",
    "\n",
    "This takes values from ($-\\infty$, $\\infty$) and outputs values from $(0, 1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**It's not very clear in this dataset, but the logistic fit looks something like this in the extreme case**\n",
    "![log_vs_ols](assets/images/log_vs_ols.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fit a logistic regression on the same data as before\n",
    "X = df1[['gre']]\n",
    "y = df1['admit']\n",
    "logit = linear_model.LogisticRegression().fit(X, y)\n",
    "logit_pred = logit.predict_proba(X)[:, 1]\n",
    "# predict_proba return the probability of every class\n",
    "# In this case we have two classes and we retrieve probabilities of positive class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot both the linear model and logistic model\n",
    "plt.figure()\n",
    "plt.scatter(X, y)\n",
    "plt.scatter(X, logit_pred, c='red')\n",
    "plt.scatter(X, lm_pred, c='green')\n",
    "plt.plot(df1.gre.mean(), df1.admit.mean(), 'ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's hard to see, but the red line is very slightly curved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ACTIVITY:  KNOWLEDGE CHECK\n",
    "\n",
    "What is the probably of a student getting accepted with a GRE score of 800?\n",
    "\n",
    "<!--\n",
    "Roughly 60-70%.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FIX 3: PROBABILITY, ODDS, e, LOG, LOG-ODDS\n",
    "\n",
    "$$probability= \\frac{one~outcome}{all~outcomes}$$\n",
    "\n",
    "$$odds= \\frac{one~outcome}{all~other~outcomes}$$\n",
    "\n",
    "Examples:\n",
    "\n",
    "    Dice roll of 1: probability = 1/6, odds = 1/5\n",
    "    Even dice roll: probability = 3/6, odds = 3/3 = 1\n",
    "    Dice roll less than 5: probability = 4/6, odds = 4/2 = 2\n",
    "\n",
    "$$odds=\\frac{probability}{1−probability}$$\n",
    "\n",
    "$$probability= \\frac{odds}{1+odds}$$\n",
    "\n",
    "Does that look familiar?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Deriving the logistic function**\n",
    "\n",
    "A convenient transformation is to take the log of odds to make the values symmetric\n",
    "$$\\log{(\\frac{p}{1-p})}$$\n",
    "\n",
    "Remember how we want y in our regression to represent the probability of a certain class?\n",
    "\n",
    "$$\\log{(\\frac{y}{1-y})} = \\alpha + \\beta X$$\n",
    "\n",
    "$$\\frac{y}{1-y} = e^{\\alpha + \\beta X}$$\n",
    "\n",
    "$$\\frac{1}{\\frac{1}{y}-1} = e^{\\alpha + \\beta X}$$\n",
    "\n",
    "$$\\frac{1}{y} = 1 + e^{-(\\alpha + \\beta X)}$$\n",
    "\n",
    "\n",
    "Once you do the algebra, this is the same as\n",
    "$$y = \\frac{1}{1 + e^{-(\\alpha + \\beta X)}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a table of probability versus odds\n",
    "odds_table = pd.DataFrame({'probability':[0.1, 0.2, 0.25, 0.5, 0.6, 0.8, 0.9]})\n",
    "odds_table['odds'] = odds_table.probability/(1 - odds_table.probability)\n",
    "odds_table['log_odds'] = np.log(odds_table['odds'])\n",
    "odds_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "logit.coef_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNOWLEDGE CHECK\n",
    "\n",
    "Pretend the coefficient on gre is 0.00160551. How do we interpret this?\n",
    "\n",
    "<!--\n",
    "ANSWER:\n",
    "This means that the log-odds of admittance go up by 0.00160551 for a unit increase in GRE\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# INDEPENDENT PRACTICE\n",
    "\n",
    "LOGISTIC REGRESSION IMPLEMENTATION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## ACTIVITY: LOGISTIC REGRESSION IMPLEMENTATION\n",
    "DIRECTIONS (15 minutes)\n",
    "\n",
    "Use the data collegeadmissions.csv and the LogisticRegression estimator in sklearn to predict the target variable admit.  \n",
    "\n",
    "1. What is the bias, or prior probability, of the dataset?\n",
    "2. Build a simple model with one feature and explore the coef_ value.  Does this represent the odds or logit (log odds)?\n",
    "3. Build a more complicated model using multiple features.  Interpreting the odds, which features have the most impact on admission rate?  Which features have the least?\n",
    "4. What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model, cross_validation, metrics\n",
    "\n",
    "admissions = pd.read_csv('assets/dataset/admissions.csv')\n",
    "admissions = admissions.dropna()\n",
    "# get dummy variables for prestige\n",
    "admissions = admissions.join(pd.get_dummies(admissions['prestige'], prefix='prestige'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1. What is the bias, or prior probability, of the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 2. Build a simple model with one feature and explore the coef_ value.  Does this represent the odds or logit (log odds)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 3. Build a more complicated model using multiple features.  Interpreting the odds, which features have the most impact on admission rate?  Which features have the least?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 4. What is the accuracy of your model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADVANCED CLASSIFICATION METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Accuracy is only one of several metrics used when solving a classification problem.\n",
    "\n",
    "$$Accuracy = \\frac{total~predicted~correct}{total~predicted}$$\n",
    "\n",
    "Accuracy alone doesn’t always give us a full picture.\n",
    "\n",
    "If we know a model is 75% accurate, it doesn’t provide any insight into why the 25% was wrong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider a binary classification problem where we have 165 observations/rows of people who are either smokers or non-smokers. \n",
    "\n",
    "<table width=150px style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 60 in class 0, non-smokers, and 105 observations in class 1, smokers\n",
    "<table width=150px style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 55 predictions of class, predicted as non-smoker and 110 of class 1, predicted to be a smoker\n",
    "\n",
    "<table width=150px style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\"></td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **true positives (TP):** These are cases in which we predicted yes (smokers), and they actually are smokers.\n",
    "- **true negatives (TN):** We predicted no, and they are non-smokers.\n",
    "- **false positives (FP):** We predicted yes, but they were not actually smokers. (Also known as a \"Type I error.\")\n",
    "- **false negatives (FN):** We predicted no, but they are smokers. (Also known as a \"Type II error.\")\n",
    "<table width=150px style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNOWLEDGE CHECK\n",
    "\n",
    "Try not to look at the answers above.\n",
    "\n",
    "Categorize these as TP, TN, FP, FN:\n",
    "    \n",
    "- We predict non-smoker, but the person is a smoker\n",
    "- We predict non-smoker, and the person is a non-smoker\n",
    "- We predict smoker and the person is a smoker\n",
    "- We predict smoker and the persin is a non-smoker\n",
    "\n",
    "<!--\n",
    "ANSWER\n",
    "- FP\n",
    "- TN\n",
    "- TP\n",
    "- FP\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SIMPLE METRICS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Accuracy:** Overall, how often is the classifier correct?\n",
    "\n",
    "<span>\n",
    "    (<span style=\"color: green\">TP</span>+<span style=\"color: red\">TN</span>)/<span style=\"color: blue\">total</span> = (<span style=\"color: green\">100</span>+<span style=\"color: red\">50</span>)/<span style=\"color: blue\">165</span> = 0.91\n",
    "</span>\n",
    "\n",
    "<table width=150px style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom; color: blue\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center; background-color: red\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center; background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**True Positive Rate (TPR)** asks, “Out of all of the target class labels, how many were accurately predicted to belong to that class?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it correctly identify patients with cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: green\">TP</span>/<span style=\"color: blue\">actual yes</span> = <span style=\"color: green\">100</span>/<span style=\"color: blue\">105</span> = 0.95\n",
    "</span>\n",
    "\n",
    "<table width=150px style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center\">FP = 10</td>\n",
    "    <td style=\"text-align: center\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center;background-color: green\">TP = 100</td>\n",
    "    <td style=\"text-align: center;color: blue\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**False Positive Rate (FPR)** asks, “Out of all items not belonging to a class label, how many were predicted as belonging to that target class label?”\n",
    "\n",
    "For example, given a medical exam that tests for cancer, how often does it trigger a “false alarm” by incorrectly saying a patient has cancer?\n",
    "\n",
    "<span>\n",
    "<span style=\"color: orange\">FP</span>/<span style=\"color: blue\">actual no</span> = <span style=\"color: orange\">10</span>/<span style=\"color: blue\">60</span> = 0.17\n",
    "</span>\n",
    "\n",
    "<table width=150px style=\"border: none\">\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none; vertical-align: bottom\">n = 165</td>\n",
    "    <td style=\"\"><b>Predicted: No</b></td>\n",
    "    <td style=\"\"><b>Predicted: Yes</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: No</b></td>\n",
    "    <td style=\"text-align: center\">TN = 50</td>\n",
    "    <td style=\"text-align: center;background-color: orange\">FP = 10</td>\n",
    "    <td style=\"text-align: center;color:blue\">60</td>\n",
    "</tr>\n",
    "<tr>\n",
    "    <td><b>Actual: Yes</b></td>\n",
    "    <td style=\"text-align: center\">FN = 5</td>\n",
    "    <td style=\"text-align: center\">TP = 100</td>\n",
    "    <td style=\"text-align: center\">105</td>\n",
    "</tr>\n",
    "<tr style=\"border: none\">\n",
    "    <td style=\"border: none\"></td>\n",
    "    <td style=\"text-align: center\">55</td>\n",
    "    <td style=\"text-align: center\">110</td>\n",
    "</tr>\n",
    "\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNOWLEDGE CHECK\n",
    "\n",
    "Can you see that we might weigh TPR AND FPR differently depending on the sitution?\n",
    "\n",
    "- Give an example when we care about TPR, but not FPR\n",
    "- Give an example when we care about FPR, but not TPR\n",
    "\n",
    "<!--\n",
    "ANSWER:\n",
    "- During initial medical diagnosis, we want to be sensitive. We want intial screens to come up a lot of True Positives even if we get a lot of False Positives.\n",
    "- If we are doing spam detection we want to be precise. Anything that we remove from an inbox must be spam, which may mean accepting fewer True Positives.\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**More trade-offs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The true positive and false positive rates gives us a much clearer pictures of where predictions begin to fall apart.\n",
    "\n",
    "This allows us to adjust our models accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import linear_model, cross_validation, metrics\n",
    "\n",
    "admissions = pd.read_csv('assets/dataset/admissions.csv')\n",
    "admissions = admissions.dropna()\n",
    "# get dummy variables for prestige\n",
    "admissions = admissions.join(pd.get_dummies(admissions['prestige'], prefix='prestige'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = admissions[['gre']]\n",
    "y = admissions['admit']\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(X, y, random_state=46)\n",
    "logit_simple = linear_model.LogisticRegression().fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get probability predictions\n",
    "logit_pred_proba = logit_simple.predict_proba(X_test)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_true=y_test, y_pred=logit_pred_proba > .5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNOWLEDGE CHECK\n",
    "- What is our accuracy on the test set?\n",
    "- True Positive Rate?\n",
    "- False Positive Rate?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "A good classifier would have a true positive rate approaching 1 and a false positive rate approaching 0.\n",
    "\n",
    "In our smoking problem, this model would accurately predict all of the smokers as smokers and not accidentally predict any of the nonsmokers as smokers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can vary the classification threshold for our model to get different predictions.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "metrics.confusion_matrix(y_true=y_test, y_pred=logit_pred_proba > .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**But how do we know if a model is better overall than other model?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It can often be difficult to optimize two numbers at once.\n",
    "\n",
    "Logically, we like a single number for optimization.\n",
    "\n",
    "Can you think of any ways to combine our two metrics?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This is where the **Receiver Operation Characteristic (ROC) curve** comes in handy.\n",
    "\n",
    "The curve is created by plotting the **true positive rate** against the **false positive rate** at various model threshold settings.\n",
    "\n",
    "**Area Under the Curve (AUC)** summarizes the impact of **TPR** and **FPR** in one single value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, logit_pred_proba)\n",
    "plt.plot(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What does it actually mean?**\n",
    "- Consider the ideal classifier. \n",
    "- It only makes True Positives and True Negatives. \n",
    "- Naturally True Positives are associated with probabilities of near 1 while True Negatives are associated with probabilities of near 0.\n",
    "\n",
    "**What happens when we adjust a threshold for prediction?**\n",
    "- A threshold of 1 gives us no True Positives, hence a TPR of 0\n",
    "- A lower threshold either produces a True Positive or a False Positive\n",
    "- Eventually we run out of positives and being producing True Negatives and False Negatives\n",
    "- In the chart, starting from (0, 0), this means that each threshold change either moves the line up for a TP or the line right for a FP.\n",
    "- http://stats.stackexchange.com/questions/105501/understanding-roc-curve\n",
    "\n",
    "**What is the best ROC curve?**\n",
    "- We want a curve that sticks to the upper left hand corner\n",
    "- This means all True Positives come first and True Negatives come later\n",
    "- ROC actually measures if we ranked probabilities in the correct order\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "With this curve, we can find the **Area Under the Curve (AUC)** which summarizes the relationship in the ROC as a single number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# IMPORTANT: first argument is true values, second argument is predicted probabilities\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, logit_simple.predict_proba(X_test)[:,1])\n",
    "plt.plot(fpr, tpr)\n",
    "plt.fill_between(fpr, tpr)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "If we have a TPR of 1 (all positives are marked positive) and FPR of 0 (all negatives are not marked positive), we’d have an AUC of 1.  This means everything was accurately predicted.\n",
    "\n",
    "If we have a TPR of 0 (all positives are not marked positive) and an FPR of 1 (all negatives are marked positive), we’d have an AUC of 0.  This means nothing was predicted accurately.\n",
    "\n",
    "An AUC of 0.5 would suggest randomness (somewhat) and is an excellent benchmark to use for comparing predictions (i.e. is my AUC above 0.5?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**When should I use AUC?**\n",
    "- Ranking problems -- When you need a most likely to be true prediction rather than a full set of predictions. Or when only the relative order of your predictions matters (optimization)\n",
    "- AUC is robust to class imbalance since it considers all thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are several other common metrics when dealing with classification\n",
    "- [Accuracy](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score)\n",
    " - total correct\n",
    "- [Precision](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html#sklearn.metrics.precision_score)\n",
    " - The precision is intuitively the ability of the classifier not to label as positive a sample that is negative.\n",
    "- [Sensitivty/Recall/(1 - FPR)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html#sklearn.metrics.recall_score)\n",
    " - The recall is intuitively the ability of the classifier to find all the positive samples.\n",
    "- [Area Under the Curve (AUC)](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html#sklearn.metrics.roc_auc_score)\n",
    " - http://stats.stackexchange.com/questions/105501/understanding-roc-curve\n",
    " - http://stats.stackexchange.com/questions/132777/what-does-auc-stand-for-and-what-is-it\n",
    "\n",
    "Sklearn has all of the metrics located on one convenient page.\n",
    "http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BREAK"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### EXERCISE: WHICH METRIC SHOULD I USE?\n",
    "\n",
    "While AUC seems like a “golden standard”, it could be further improved depending upon your problem.  There will be instances where error in positive or negative matches will be very important.\n",
    "\n",
    "For each of the following examples: \n",
    "\n",
    "1. Write a confusion matrix: true positive, false positive, true negative, false negative. Then decide what each square represents for that specific example.\n",
    "2. Choose a classification metric that seems appropriate for the problem\n",
    "\n",
    "\n",
    "- A test is developed for determining if a patient has cancer or not.\n",
    "- A newspaper company is targeting a marketing campaign for \"at risk\" users that may stop paying for the product soon.\n",
    "- You build a spam classifier for your email system.\n",
    "- Customer e-mails are classified as complaint or compliment. You want an algorithm to help you identify complaints so you can address them first\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INDEPENDENT PRACTICE\n",
    "\n",
    "EVALUATING LOGISTIC REGRESSION WITH ALTERNATIVE METRICS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ACTIVITY: EVALUATING LOGISTIC REGRESSION\n",
    "DIRECTIONS (35 minutes)\n",
    "EXERCISE\n",
    "\n",
    "Kaggle’s common online exercise is exploring survival data from the Titanic.\n",
    "https://www.kaggle.com/c/titanic\n",
    "    \n",
    "Spend a few minutes determining which data would be most important to use in the prediction problem. You may need to create new features based on the data available.\n",
    "Build a tuned Logistic model. Use the unit project 3 starter code as a template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TOPIC REVIEW\n",
    "\n",
    "What’s the link function used in logistic regression?\n",
    "\n",
    "What kind of machine learning problems does logistic regression address?\n",
    "\n",
    "What do the coefficients in a logistic regression represent? How does the interpretation differ from ordinary least squares? How is it similar?\n",
    "\n",
    "\n",
    "How does True Positive Rate and False Positive Rate help explain accuracy?\n",
    "\n",
    "What would an AUC of 0.5 represent for a model? What about an AUC of 0.9?\n",
    "\n",
    "Why might one classification metric be more important to tune than another? Give an example of a business problem or project where this would be the case.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEFORE NEXT CLASS\n",
    "- Start working on Unit project 4 DUE Monday (this is a long one)\n",
    "  - https://github.com/ga-students/DS-DC-14/tree/master/projects/unit-projects/project-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADDITIONAL RESOURCES\n",
    "- http://www.dataschool.io/simple-guide-to-confusion-matrix-terminology/\n",
    "- http://www.dataschool.io/roc-curves-and-auc-explained/\n",
    "\n",
    "A good example of making trade-offs in practical situations\n",
    "- http://blog.insightdatalabs.com/visualizing-classifier-thresholds/\n",
    "\n",
    "Cross-Validated:\n",
    "- http://stackoverflow.com/questions/tagged/logistic-regression\n",
    "- FAQ's on cross-validated for AUC and Confusion Matrix don't look great\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LESSON: INTRO TO LOGISTIC REGRESSION\n",
    "EXIT TICKET \n",
    "\n",
    "DON’T FORGET TO FILL OUT YOUR EXIT TICKET\n",
    "\n",
    "http://goo.gl/forms/gG5qAw9QljgkHC2q1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
